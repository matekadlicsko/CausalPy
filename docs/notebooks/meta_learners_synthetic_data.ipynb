{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafe7c80-fc2d-47d4-b260-c5a1082d6fbb",
   "metadata": {},
   "source": [
    "# Comparing meta-learners with different ensembles of trees as base learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc6766-7606-4b6b-8c76-b4b5b732c988",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Meta-learners are a class of models used for estimating the effectiveness of a certain treatement and they are used when the effectiveness of a treatement is assumed to be *heterogeneous*, that is the effect of the treatement might vary across individuals. In particular, they estimate the treatement effectiveness by decomposing the problem to several subregressions. The models used for these subregressions will be called *base learners*. Some of the most popular base learners are tree based ensembles, in particular Random Forest and Bayesian Additive Regression Trees (BART) due to their flexibility, however any machine learning algorithm suitable for regression problems can be used.\n",
    "\n",
    "Following [1], we will denote by $Y$ an outcome vector, by $X_i \\in \\mathbb{R}^d$ a feature vector containing potential confounders for the $i$th unit, by $W_i \\in \\{0, 1\\}$ the treatment assignment indicator and by  $Y_i (0) \\in \\mathbb{R}$ and $Y_i(1) \\in \\mathbb{R}$ the potential outcome of the $i$th unit when assigned to the control and the treatement group respectively. With this notation\n",
    "\n",
    "$$ Y = W Y(1) + (1 - W) Y(0). $$\n",
    "\n",
    "Our task is to estimate the *conditional average treatement effect (CATE)*, defined as \n",
    "$$\\tau(x) = \\mathbb{E}\\left[Y(1) - Y(0) \\mid X=x\\right].$$\n",
    "\n",
    "The goal of this notebook is to introduce several meta-learners and compare their performance estimating CATE. The evaluation of an estimation $\\hat{\\tau}$ of $\\tau$ will be based on *expected mean squared error* defined as \n",
    "$$\\operatorname{EMSE}(\\tau) = \\mathbb{E}\\left[\\left(\\tau(X) - \\hat{\\tau}(X)\\right)^2\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73c7c9-7df5-4912-80f4-c5e69c916c22",
   "metadata": {},
   "source": [
    "## The fundamental problem of causal inference\n",
    "\n",
    "The fact that only one of the potential outcomes ever materializes, means that CATE is never directly observed, thus on real world data, EMSE cannot be computed. This is often refered to as *the fundamental problem of causal inference*. To get around this problem, in this notebook we will deal with synthetic data with data generating process of the form\n",
    "$$y = \\sigma(\\alpha X) + W \\sigma(\\beta X) + \\varepsilon,$$\n",
    "where $\\varepsilon_i \\sim N(0, 1)$ and $W_i \\sim \\operatorname{Bernoulli}\\left(\\frac12\\right)$ are i.i.d. and $$\\sigma(x) = \\frac{e^x}{1 + e^x}$$ is the sigmoid function (applied coordinatewise).\n",
    "Here, CATE can be expressed as $\\tau(X) = \\sigma(\\beta X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c543b717-acb7-4c7f-aa77-975833dbf699",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x) / (1 + np.exp(x))\n",
    "\n",
    "def create_synthetic_data(*shape):\n",
    "    X = np.random.rand(*shape)\n",
    "\n",
    "    α = np.random.rand(shape[1])\n",
    "    β = np.random.rand(shape[1])\n",
    "\n",
    "    treatment = np.random.randint(low=0, high=2, size=shape[0])\n",
    "    treatment_effect = sigmoid(X @ β)\n",
    "\n",
    "    noise = np.random.rand(shape[0])\n",
    "\n",
    "    y = sigmoid(X @ α) + treatment_effect * treatment + noise\n",
    "\n",
    "    X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(shape[1])])\n",
    "    y = pd.Series(y, name='target')\n",
    "    treated = pd.Series(treatment, name='treatment')\n",
    "    return X, y, treated, treatment_effect\n",
    "\n",
    "synth_data = create_synthetic_data(1000, 6)\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    treated_train,\n",
    "    treated_test,\n",
    "    effect_train,\n",
    "    effect_test\n",
    ") = train_test_split(*synth_data, test_size=.5, stratify=synth_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf837e1-d93c-4fc5-bc52-96296db82e51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## S-learner\n",
    "\n",
    "The simplest meta-learner is the *S-learner*, which treats the treatement assignment indicator as a feature and estimates \n",
    "\n",
    "$$\\mu(x, w) := \\mathbb{E}[Y \\mid X=x, W=w]$$\n",
    "\n",
    "with an appropriate base learner. The \"S\" in S-learner stands for \"single\", as it uses a single model to estimate CATE. We will denote this estimation with $\\hat{\\mu}(x, w)$. Then the S-learner approximates CATE as  \n",
    "\n",
    "$$\\hat{\\tau_S}(x) = \\hat{\\mu}(x, 1) - \\hat{\\mu}(x, 0).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454322d0-6dbc-4771-bb7a-344afa30e793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:             500\n",
      "Number of treated observations:     260\n",
      "Average treatement effect (ATE):    0.7934167385101318\n",
      "95% Confidence interval for ATE:    (0.48431164473295213, 1.2554474145174028)\n",
      "Estimated bias:                     0.01015559397637844\n",
      "Actual average treatement effect: 0.8166310319237063\n",
      "EMSE: 0.04852673729489554\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from skl_meta_learners import SLearner\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "slearner_xgb = SLearner(X=X_train, y=y_train, treated=treated_train, model=XGBRegressor())\n",
    "\n",
    "\n",
    "slearner_xgb.summary(n_iter=100)\n",
    "print(f\"Actual average treatement effect: {effect_train.mean()}\")\n",
    "print(f\"EMSE: {mean_squared_error(effect_train, slearner_xgb.cate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552d0e9-5d6c-4d4b-bde8-80c680a51e62",
   "metadata": {},
   "source": [
    "**TODO: Do some plotting. As of now it plots the distribution of the CATE estimates. While that is not totally uninteresting, it is not good either.**\n",
    "\n",
    "More ideas: \n",
    "- feature to estimated CATE scatter plot?\n",
    "- several SHAP related things?\n",
    "- ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059fd652-3fa9-42d3-b639-a48d96263314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slearner_xgb.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe391b5-d8df-438f-ace2-0406d19e5813",
   "metadata": {},
   "source": [
    "Eventough, the S-learner performs quite well in our synthetic example, it has some limitations. Most importantly, since the treatement indicator is included in the regression as an ordinary variable, it's effect may get lost, especially if the base learner is a tree based ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d35f7f-6526-4b7d-ac36-2365fc08cb5d",
   "metadata": {},
   "source": [
    "## T-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8971c-5eef-4423-893e-9277e8a40ac1",
   "metadata": {},
   "source": [
    "The *T-learner* solves the issue mentioned above by predicting $Y(0)$ and $Y(1)$ in two different regressions. Namely, we estimate\n",
    "$$\\mu_{\\operatorname{treated}}(x) := \\mathbb{E}[Y(1) \\mid X=x], \\quad \\text{and} \\quad \\mu_{\\operatorname{untreated}}(x) := \\mathbb{E}[Y(0) \\mid X=x]$$\n",
    "separately and define estimate the cate as \n",
    "$$\\hat{\\tau}_T(x) = \\mu_{\\operatorname{treated}}(x) - \\mu_{\\operatorname{untreated}}(x).$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a24a76e-398a-4629-9d49-7fadecb2a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:             500\n",
      "Number of treated observations:     260\n",
      "Average treatement effect (ATE):    0.7737631797790527\n",
      "95% Confidence interval for ATE:    (0.39325197115540506, 1.380606359243393)\n",
      "Estimated bias:                     0.0014979877742007375\n",
      "Actual average treatement effect: 0.8166310319237063\n",
      "EMSE: 0.10909539371677517\n"
     ]
    }
   ],
   "source": [
    "from skl_meta_learners import TLearner\n",
    "\n",
    "tlearner_xgb = TLearner(X=X_train, y=y_train, treated=treated_train, model=XGBRegressor())\n",
    "\n",
    "\n",
    "tlearner_xgb.summary(n_iter=100)\n",
    "print(f\"Actual average treatement effect: {effect_train.mean()}\")\n",
    "print(f\"EMSE: {mean_squared_error(effect_train, tlearner_xgb.cate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef7acd-3d29-4b2a-b364-a915a30f4f46",
   "metadata": {},
   "source": [
    "# X-learner\n",
    "The X-learner ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "250bd516-b1ad-452f-b26c-e0eafc3747f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:             500\n",
      "Number of treated observations:     260\n",
      "Average treatement effect (ATE):    0.7781170069093923\n",
      "95% Confidence interval for ATE:    (0.5208629256497909, 1.211836616459581)\n",
      "Estimated bias:                     0.005161760576251569\n",
      "Actual average treatement effect: 0.8166310319237063\n",
      "EMSE: 0.06922727984762232\n"
     ]
    }
   ],
   "source": [
    "from skl_meta_learners import XLearner\n",
    "\n",
    "xlearner_xgb = XLearner(X=X_train, y=y_train, treated=treated_train, model=XGBRegressor())\n",
    "\n",
    "\n",
    "xlearner_xgb.summary(n_iter=100)\n",
    "print(f\"Actual average treatement effect: {effect_train.mean()}\")\n",
    "print(f\"EMSE: {mean_squared_error(effect_train, xlearner_xgb.cate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a499cc5-2fcf-4016-978b-c3c28c861d5a",
   "metadata": {},
   "source": [
    "# DR-learner\n",
    "The DR-learner ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687aa584-b8af-4863-a7cf-570e86080057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:             500\n",
      "Number of treated observations:     260\n",
      "Average treatement effect (ATE):    0.7738259434700012\n",
      "95% Confidence interval for ATE:    (0.38628790229558946, 1.3743409484624864)\n",
      "Estimated bias:                     -0.002300022169947624\n",
      "Actual average treatement effect: 0.8166310319237063\n",
      "EMSE: 0.10963045326355204\n"
     ]
    }
   ],
   "source": [
    "from skl_meta_learners import DRLearner\n",
    "\n",
    "drlearner_xgb = DRLearner(X=X_train, y=y_train, treated=treated_train, model=XGBRegressor())\n",
    "\n",
    "\n",
    "drlearner_xgb.summary(n_iter=100)\n",
    "print(f\"Actual average treatement effect: {effect_train.mean()}\")\n",
    "print(f\"EMSE: {mean_squared_error(effect_train, drlearner_xgb.cate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "648ef110-5a67-4eca-8ff0-0ddb0308c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2cc2c39-2690-4943-90a9-b90fd2a60972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emse(learner, m):\n",
    "    l = learner(X_train, y_train, treated_train, m)\n",
    "    return mean_squared_error(effect_train, l.cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3552a561-8051-4a51-832a-5e088a106689",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Random forest\", RandomForestRegressor()),\n",
    "    (\"Hist gradient boosting\", HistGradientBoostingRegressor()),\n",
    "    (\"AdaBoost\", AdaBoostRegressor()),\n",
    "    (\"XGBoost\", XGBRegressor()),\n",
    "    (\"LightGBM\", LGBMRegressor())\n",
    "]\n",
    "bench = pd.DataFrame({\n",
    "    m_name: {\n",
    "            'SLearner':  compute_emse( SLearner, m),\n",
    "            'TLearner':  compute_emse( TLearner, m),\n",
    "            'XLearner':  compute_emse( XLearner, m),\n",
    "            'DRLearner': compute_emse(DRLearner, m)\n",
    "        } for m_name, m in models\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eed6094-c940-4b5b-8294-bd2ffeab2eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Hist gradient boosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLearner</th>\n",
       "      <td>0.043266</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.048527</td>\n",
       "      <td>0.030729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLearner</th>\n",
       "      <td>0.045308</td>\n",
       "      <td>0.055968</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.109095</td>\n",
       "      <td>0.052863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLearner</th>\n",
       "      <td>0.027551</td>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.069227</td>\n",
       "      <td>0.041362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRLearner</th>\n",
       "      <td>0.164998</td>\n",
       "      <td>0.179821</td>\n",
       "      <td>0.279397</td>\n",
       "      <td>0.109630</td>\n",
       "      <td>0.184410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random forest  Hist gradient boosting  AdaBoost   XGBoost  LightGBM\n",
       "SLearner        0.043266                0.028720  0.005436  0.048527  0.030729\n",
       "TLearner        0.045308                0.055968  0.011586  0.109095  0.052863\n",
       "XLearner        0.027551                0.042998  0.008828  0.069227  0.041362\n",
       "DRLearner       0.164998                0.179821  0.279397  0.109630  0.184410"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a6965-0ef3-4d7b-93d8-138b7602517a",
   "metadata": {},
   "source": [
    "# TODO: EMSE as a function of population size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
